{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports and Data Wrangling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ba0f7b0f1257e26"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "historiography = {\n",
    "    \"herodotus\",\n",
    "    \"thucydides\",\n",
    "    \"xenophon\",\n",
    "    \"polybius\",\n",
    "    \"plutarch\"\n",
    "}\n",
    "\n",
    "poetry = {\n",
    "    \"homer\",\n",
    "    \"hesiod\",\n",
    "    \"apollonius\",\n",
    "    \"callimachus\",\n",
    "    \"theocritus\",\n",
    "    \"pindar\"\n",
    "}\n",
    "\n",
    "author_target = {\"herodotus\":0,\n",
    "           \"thucydides\":1,\n",
    "           \"xenophon\":2,\n",
    "           \"polybius\":3,\n",
    "           \"plutarch\":4,\n",
    "           \"homer\":5,\n",
    "           \"hesiod\":6,\n",
    "           \"apollonius\":7, \n",
    "           \"callimachus\":8,\n",
    "           \"theocritus\":9,\n",
    "           \"pindar\":10}\n",
    "\n",
    "genre_target = {'poetry':0, 'history':1}\n",
    "\n",
    "def standardize_accents(target_token):\n",
    "    token = target_token.replace('ὰ', 'ά')\n",
    "    token = token.replace('ἂ', 'ἄ')\n",
    "    token = token.replace('ἃ', 'ἅ')\n",
    "    token = token.replace('ὲ', 'έ')\n",
    "    token = token.replace('ἒ', 'ἔ')\n",
    "    token = token.replace('ἓ', 'ἕ')\n",
    "    token = token.replace('ὴ', 'ή')\n",
    "    token = token.replace('ἢ', 'ἤ')\n",
    "    token = token.replace('ἣ', 'ἥ')\n",
    "    token = token.replace('ὶ', 'ί')\n",
    "    token = token.replace('ἲ', 'ἴ')\n",
    "    token = token.replace('ἳ', 'ἵ')\n",
    "    token = token.replace('ῒ', 'ΐ')\n",
    "    token = token.replace('ὸ', 'ό')\n",
    "    token = token.replace('ὂ', 'ὄ')\n",
    "    token = token.replace('ὃ', 'ὅ')\n",
    "    token = token.replace('ὺ', 'ύ')\n",
    "    token = token.replace('ὒ', 'ὔ')\n",
    "    token = token.replace('ὓ', 'ὕ')\n",
    "    token = token.replace('ῢ', 'ΰ')\n",
    "    token = token.replace('ὼ', 'ώ')\n",
    "    token = token.replace('ὢ', 'ὤ')\n",
    "    token = token.replace('ὣ', 'ὥ')\n",
    "    token = token.replace('ᾲ', 'ᾴ')\n",
    "    token = token.replace('ᾂ', 'ᾄ')\n",
    "    token = token.replace('ᾃ', 'ᾅ')\n",
    "    token = token.replace('ῂ', 'ῄ')\n",
    "    token = token.replace('ᾒ', 'ᾔ')\n",
    "    token = token.replace('ᾓ', 'ᾕ')\n",
    "    token = token.replace('ῲ', 'ῴ')\n",
    "    token = token.replace('ᾢ', 'ᾤ')\n",
    "    token = token.replace('ᾣ', 'ᾥ')\n",
    "    token = token.replace('Ὰ', 'Ά')\n",
    "    token = token.replace('Ἂ', 'Ἄ')\n",
    "    token = token.replace('Ἃ', 'Ἅ')\n",
    "    token = token.replace('Ὲ', 'Έ')\n",
    "    token = token.replace('Ἒ', 'Ἔ')\n",
    "    token = token.replace('Ἓ', 'Ἕ')\n",
    "    token = token.replace('Ὴ', 'Ή')\n",
    "    token = token.replace('Ἢ', 'Ἤ')\n",
    "    token = token.replace('Ἣ', 'Ἥ')\n",
    "    token = token.replace('Ὶ', 'Ί')\n",
    "    token = token.replace('Ἲ', 'Ἴ')\n",
    "    token = token.replace('Ἳ', 'Ἵ')\n",
    "    token = token.replace('Ὸ', 'Ό')\n",
    "    token = token.replace('Ὂ', 'Ὄ')\n",
    "    token = token.replace('Ὃ', 'Ὅ')\n",
    "    token = token.replace('Ὺ', 'Ύ')\n",
    "    token = token.replace('Ὓ', 'Ὕ')\n",
    "    token = token.replace('Ὼ', 'Ώ') \n",
    "    token = token.replace('Ὢ', 'Ὤ')\n",
    "    token = token.replace('Ὣ', 'Ὥ')\n",
    "    token = token.replace('ᾊ', 'ᾌ')\n",
    "    token = token.replace('ᾋ', 'ᾍ')\n",
    "    token = token.replace('ᾚ', 'ᾜ')\n",
    "    token = token.replace('ᾛ', 'ᾝ')\n",
    "    token = token.replace('ᾪ', 'ᾬ')\n",
    "    token = token.replace('ᾫ', 'ᾭ')\n",
    "    return token\n",
    "\n",
    "def is_wine_line(line):\n",
    "    standardized_line = standardize_accents(line)\n",
    "    wine_forms = ['οἶνος', 'οἴνου', 'οἴνῳ', 'οἶνον', 'οἴνω', 'οἶνοι', 'οἴνου', 'οἴνῳ', 'οἶνον', 'οἶνε', 'οἴνοιν', 'οἴνω','οἴνων', 'οἴνοις', 'οἴνους', 'χοἷνος', 'οἶνων', 'οἴνωι', 'οἴνω', 'οἷνου', 'οἵνου', 'οἶνου', 'οἴνου', 'ὀίνου', 'ὄινου', 'οίνου', 'οινου', 'οἷνος', 'οἶνος', 'οινος',  'οἷνον', 'οἵνον', 'οἶνον', 'οἴνον', 'οινον', 'οἴνοισιν', 'οἴνοισι', 'οἴνοις', 'οἴνοιο','οἶνοι','οἶνο','οἶνε','οίνε','κᾦνος','κᾦνον','ϝοῖνον','γοῖνος']\n",
    "    for form in wine_forms:\n",
    "        if form in standardized_line.split(\" \"):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def clean_files_to_df(quiet=True):\n",
    "    \"\"\"Reads all csv files in data to a pandas dataframe.\"\"\"\n",
    "    path = os.getcwd() + '\\data_clean'\n",
    "    text_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    header = ['genre', 'author', 'work', 'section', 'line_number','string', 'wine_line']\n",
    "    all_lines = []\n",
    "    for file in text_files:\n",
    "        if not quiet:\n",
    "            print('File Name:', file.split(\"\\\\\")[-1])\n",
    "        file_tokens = (file.split(\"\\\\\")[-1]).split(\"_\")\n",
    "        author = file_tokens[0]\n",
    "        work = file_tokens[1]\n",
    "        if author in historiography:\n",
    "            genre = 'history'\n",
    "        elif author in poetry:\n",
    "            genre = 'poetry'\n",
    "        if len(file_tokens) == 4:\n",
    "            section = file_tokens[2]\n",
    "        else:\n",
    "            section = \"NA\"\n",
    "        # open and read file             \n",
    "        open_file = open(file, 'r', encoding='utf8')\n",
    "        file_lines = open_file.readlines()\n",
    "        line_number = 1\n",
    "        for line in file_lines:\n",
    "            if len(line.split(' '))>3:\n",
    "                wine = is_wine_line(line.strip())\n",
    "                line = line.replace(\"†\", \"\")\n",
    "                line = line.replace('\"\"', '')\n",
    "                line = line.replace('…', '')\n",
    "                line = line.replace(\"'\", \"\")\n",
    "                line = line.replace('”', \"\")\n",
    "                line = line.replace('“', '')\n",
    "                line = line.replace('—', '')\n",
    "                line = line.replace('῾', '')\n",
    "                line = line.replace('\"', '')\n",
    "                line = line.replace(\"!\", '')\n",
    "                line = line.replace('*', '')\n",
    "                line = line.replace('-', '')\n",
    "                line = line.replace('>', '')\n",
    "                all_lines.append([genre, author, work, section, line_number, line.strip(), wine])\n",
    "                line_number += 1\n",
    "    corpus_df = pd.DataFrame(all_lines, columns=header)\n",
    "    return corpus_df\n",
    "\n",
    "def process_text(text_processing):\n",
    "    text_processing = str(text_processing).lower()\n",
    "    text_processing = re.sub(\n",
    "        f\"[{re.escape(string.punctuation)}]\", \" \", text_processing\n",
    "    )\n",
    "    text_processing = \" \".join(text_processing.split())\n",
    "    return text_processing\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:30:51.266911700Z",
     "start_time": "2023-12-04T20:30:48.599121500Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The lines below create a dataframe of our corpus and factorizes genre and author. I also remove all empty strings from the corpus. I define our training corpus as all the lines that do not contain οἶνος and the experiment corpus as all the lines that do contain οἶνος."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "760c1a67dbbf3eb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus = clean_files_to_df(quiet=True)\n",
    "corpus = corpus[corpus.string != \"\"]\n",
    "\n",
    "corpus['target']=corpus['genre'].map(genre_target)\n",
    "corpus['author_target']=corpus['author'].map(author_target)\n",
    "\n",
    "experiment = corpus[corpus.wine_line==True]\n",
    "training = corpus[corpus.wine_line==False]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b52238aa44985951"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification by Genre\n",
    "\n",
    "The two cell blocks below train a multinomial Naive Bayes classifier to classify lines of ancient Greek text into one of two genres, poetry and prose. We train the MNB using all the lines in the corpus that do not contain a form of οἶνος and then test the model using the 159 lines that do contain a form of οἶνος. The second cell is a control experiment that uses both training and test data from the non-οἶνος corpus. (Note: Validation sets are drawn from training data.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4af63aa0e04be004"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Experiment\n",
    "\n",
    "df = training\n",
    "df[\"clean_text\"] = df.string.map(process_text)\n",
    "df_train, df_test = train_test_split(df, test_size=0.20, stratify=df.target)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "X_train = vec.fit_transform(df_train.clean_text)\n",
    "X_test = vec.transform(df_test.clean_text)\n",
    "y_train = df_train.target\n",
    "y_test = df_test.target\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "preds = nb.predict(X_test)\n",
    "# Save the model\n",
    "joblib.dump(nb, \"nb.joblib\")\n",
    "joblib.dump(vec, \"vec.joblib\")\n",
    "# Print a report of the model's performance\n",
    "print(classification_report(y_test, preds))\n",
    "# Load the model again\n",
    "nb_saved = joblib.load(\"nb.joblib\")\n",
    "vec_saved = joblib.load(\"vec.joblib\")\n",
    "# Test the model and record the results\n",
    "all_mnb_results = []\n",
    "header=['author', 'text', 'line', 'expected', 'result']\n",
    "for index,row in experiment.iterrows():\n",
    "    line = row['string']\n",
    "    clean_line = process_text(line)\n",
    "    sample_vec = vec_saved.transform([line])\n",
    "    author = row['author']\n",
    "    text = row['work']\n",
    "    expected = row['target']\n",
    "    result = nb_saved.predict(sample_vec)\n",
    "    all_mnb_results.append([author, text, line, expected, result[0]])\n",
    "\n",
    "results_df = pd.DataFrame(all_mnb_results, columns=header)\n",
    "results_df.to_csv('mnb_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa143eda93eb704"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Control\n",
    "\n",
    "#We define our training data as 95% of the non-οἶνος corpus\n",
    "df = training.sample(frac=0.95)\n",
    "#The test data for the control experiment is the remaining 5% \n",
    "test = training.drop(df.index)\n",
    "\n",
    "df[\"clean_text\"] = df.string.map(process_text)\n",
    "df_train, df_test = train_test_split(df, test_size=0.20, stratify=df.target)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "X_train = vec.fit_transform(df_train.clean_text)\n",
    "X_test = vec.transform(df_test.clean_text)\n",
    "\n",
    "y_train = df_train.target\n",
    "y_test = df_test.target\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "preds = nb.predict(X_test)\n",
    "\n",
    "joblib.dump(nb, \"nb.joblib\")\n",
    "joblib.dump(vec, \"vec.joblib\")\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "nb_saved = joblib.load(\"nb.joblib\")\n",
    "vec_saved = joblib.load(\"vec.joblib\")\n",
    "all_mnb_results = []\n",
    "header=['author', 'text', 'line', 'expected', 'result']\n",
    "\n",
    "for index,row in test.iterrows():\n",
    "    line = row['string']\n",
    "    clean_line = process_text(line)\n",
    "    sample_vec = vec_saved.transform([line])\n",
    "    author = row['author']\n",
    "    text = row['work']\n",
    "    expected = row['target']\n",
    "    result = nb_saved.predict(sample_vec)\n",
    "    all_mnb_results.append([author, text, line, expected, result[0]])\n",
    "    \n",
    "results_df = pd.DataFrame(all_mnb_results, columns=header)\n",
    "results_df.to_csv('mnb_control_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8a4324b47e03a53"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification by Author"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3722f0d7ab819d3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The two cell blocks below train a multinomial Naive Bayes classifier to classify lines of ancient Greek text by author. We train the MNB using all the lines in the corpus that do not contain a form of οἶνος and then test the model using the 159 lines that do contain a form of οἶνος. The second cell is a control experiment that uses both training and test data from the non-οἶνος corpus. (Note: Validation sets are drawn from training data.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fa0302035e2a199"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Experiment\n",
    "\n",
    "df = training.sample(frac=0.95)\n",
    "test = training.drop(df.index)\n",
    "df[\"clean_text\"] = df.string.map(process_text)\n",
    "df_train, df_test = train_test_split(df, test_size=0.20, stratify=df.author_target)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "X_train = vec.fit_transform(df_train.clean_text)\n",
    "X_test = vec.transform(df_test.clean_text)\n",
    "\n",
    "y_train = df_train.author_target\n",
    "y_test = df_test.author_target\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "preds = nb.predict(X_test)\n",
    "\n",
    "joblib.dump(nb, \"nb.joblib\")\n",
    "joblib.dump(vec, \"vec.joblib\")\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "nb_saved = joblib.load(\"nb.joblib\")\n",
    "vec_saved = joblib.load(\"vec.joblib\")\n",
    "\n",
    "all_mnb_author_results = []\n",
    "header=['author', 'text', 'line', 'expected', 'result']\n",
    "for index,row in test.iterrows():\n",
    "    line = row['string']\n",
    "    clean_line = process_text(line)\n",
    "    sample_vec = vec_saved.transform([line])\n",
    "    author = row['author']\n",
    "    text = row['work']\n",
    "    expected = row['author_target']\n",
    "    result = nb_saved.predict(sample_vec)\n",
    "    all_mnb_author_results.append([author, text, line, expected, result[0]])\n",
    "    \n",
    "results_df = pd.DataFrame(all_mnb_author_results, columns=header)\n",
    "results_df.to_csv('mnb_author_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ceae12779f92c0a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Control\n",
    "\n",
    "#We define our training data as 95% of the non-οἶνος corpus\n",
    "df = training.sample(frac=0.95)\n",
    "test = training.drop(df.index)\n",
    "\n",
    "df[\"clean_text\"] = df.string.map(process_text)\n",
    "df_train, df_test = train_test_split(df, test_size=0.20, stratify=df.author_target)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "X_train = vec.fit_transform(df_train.clean_text)\n",
    "X_test = vec.transform(df_test.clean_text)\n",
    "\n",
    "y_train = df_train.author_target\n",
    "y_test = df_test.author_target\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "preds = nb.predict(X_test)\n",
    "\n",
    "joblib.dump(nb, \"nb.joblib\")\n",
    "joblib.dump(vec, \"vec.joblib\")\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "nb_saved = joblib.load(\"nb.joblib\")\n",
    "vec_saved = joblib.load(\"vec.joblib\")\n",
    "all_mnb_author_results = []\n",
    "header=['author', 'text', 'line', 'expected', 'result']\n",
    "for index,row in test.iterrows():\n",
    "    line = row['string']\n",
    "    clean_line = process_text(line)\n",
    "    sample_vec = vec_saved.transform([line])\n",
    "    author = row['author']\n",
    "    text = row['work']\n",
    "    expected = row['author_target']\n",
    "    result = nb_saved.predict(sample_vec)\n",
    "    all_mnb_author_results.append([author, text, line, expected, result[0]])\n",
    "    \n",
    "results_df = pd.DataFrame(all_mnb_author_results, columns=header)\n",
    "results_df.to_csv('mnb_control_author_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b9e84f445e6c4ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
